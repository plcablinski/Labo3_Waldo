{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23c3324-a95e-4519-a469-2cafe3153ea5",
   "metadata": {},
   "source": [
    "# ðŸ“¦ Paso 1: Cargar y preparar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467d4829-7de0-48a1-86ab-9e91411c8c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Datos preparados y guardados\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(\"dataset_base_features.csv\", parse_dates=[\"periodo\"])\n",
    "df[\"product_id\"] = df[\"product_id\"].astype(str)\n",
    "\n",
    "# Filtrar hasta octubre 2019\n",
    "train_df = df[df[\"periodo\"] <= \"2019-10-01\"].copy()\n",
    "\n",
    "# Seleccionar features\n",
    "exclude = [\"tn\", \"customer_id\", \"periodo\", \"product_id\"]\n",
    "y = train_df[\"tn\"]\n",
    "X = train_df.drop(columns=[col for col in exclude if col in train_df.columns])\n",
    "\n",
    "# DivisiÃ³n\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "sample_weight = np.log1p(y_train + 1)\n",
    "\n",
    "# Guardar datos\n",
    "with open(\"datos_entrenamiento.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X_train, X_val, y_train, y_val, sample_weight, X.columns.tolist()), f)\n",
    "\n",
    "print(\"âœ… Datos preparados y guardados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16552e76-b5f5-419e-83e4-3e7a0bfb35b4",
   "metadata": {},
   "source": [
    "# ðŸ” Paso 2: Entrenamiento con Optuna + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f248e86e-cc16-4898-a95e-6d7d9d87fca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\waldo\\miniconda3\\envs\\lgbmgpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-06-26 19:41:45,356] A new study created in RDB with name: prediccion_tn1\n",
      "[I 2025-06-26 19:48:41,482] Trial 0 finished with value: 0.3989116569228631 and parameters: {'n_estimators': 336, 'max_depth': 3, 'learning_rate': 0.09737529257664501, 'subsample': 0.6039020412837688, 'colsample_bytree': 0.7443139520942319, 'reg_alpha': 4.224777729322853, 'reg_lambda': 3.0830387286281704}. Best is trial 0 with value: 0.3989116569228631.\n",
      "[I 2025-06-26 19:53:55,420] Trial 1 finished with value: 0.35777260096573177 and parameters: {'n_estimators': 310, 'max_depth': 7, 'learning_rate': 0.09588908537475076, 'subsample': 0.9589489202867897, 'colsample_bytree': 0.9166959111393528, 'reg_alpha': 3.861434377677769, 'reg_lambda': 2.7564486526521312}. Best is trial 1 with value: 0.35777260096573177.\n",
      "[I 2025-06-26 19:57:47,636] Trial 2 finished with value: 0.38916045502588875 and parameters: {'n_estimators': 220, 'max_depth': 4, 'learning_rate': 0.03711336018402963, 'subsample': 0.7595944802923725, 'colsample_bytree': 0.8023881749053298, 'reg_alpha': 1.0341999862949502, 'reg_lambda': 1.849394306269131}. Best is trial 1 with value: 0.35777260096573177.\n",
      "[I 2025-06-26 20:01:27,393] Trial 3 finished with value: 0.3587274682956012 and parameters: {'n_estimators': 259, 'max_depth': 5, 'learning_rate': 0.06459407408650407, 'subsample': 0.7000135105418299, 'colsample_bytree': 0.8949603437949136, 'reg_alpha': 1.399880128617312, 'reg_lambda': 1.5075965897634886}. Best is trial 1 with value: 0.35777260096573177.\n",
      "[I 2025-06-26 20:04:40,649] Trial 4 finished with value: 0.3542343410916506 and parameters: {'n_estimators': 271, 'max_depth': 6, 'learning_rate': 0.06758516246196815, 'subsample': 0.8475779644889123, 'colsample_bytree': 0.8782388084725651, 'reg_alpha': 2.4075648905220177, 'reg_lambda': 4.3655645297897285}. Best is trial 4 with value: 0.3542343410916506.\n",
      "[I 2025-06-26 20:08:45,826] Trial 5 finished with value: 0.4016603762695839 and parameters: {'n_estimators': 347, 'max_depth': 3, 'learning_rate': 0.051001375007203906, 'subsample': 0.6951361586005482, 'colsample_bytree': 0.7011390970124729, 'reg_alpha': 1.5678533659445193, 'reg_lambda': 3.0095571028128854}. Best is trial 4 with value: 0.3542343410916506.\n",
      "[I 2025-06-26 20:13:12,489] Trial 6 finished with value: 0.3690301096994618 and parameters: {'n_estimators': 247, 'max_depth': 7, 'learning_rate': 0.09527843545857488, 'subsample': 0.6328112899887707, 'colsample_bytree': 0.8002383895269117, 'reg_alpha': 0.5932113859498356, 'reg_lambda': 2.208234944826151}. Best is trial 4 with value: 0.3542343410916506.\n",
      "[I 2025-06-26 20:17:36,374] Trial 7 finished with value: 0.35994211968256257 and parameters: {'n_estimators': 204, 'max_depth': 5, 'learning_rate': 0.054157124012154154, 'subsample': 0.6688318052671197, 'colsample_bytree': 0.7909549734186844, 'reg_alpha': 1.9599736530487895, 'reg_lambda': 2.5468595911691776}. Best is trial 4 with value: 0.3542343410916506.\n",
      "[I 2025-06-26 20:20:25,168] Trial 8 finished with value: 0.4189324030579899 and parameters: {'n_estimators': 159, 'max_depth': 3, 'learning_rate': 0.0791889156018335, 'subsample': 0.7949808418129598, 'colsample_bytree': 0.8576839576642793, 'reg_alpha': 1.661604566783717, 'reg_lambda': 4.877805016576519}. Best is trial 4 with value: 0.3542343410916506.\n",
      "[I 2025-06-26 20:23:17,639] Trial 9 finished with value: 0.4238468077647208 and parameters: {'n_estimators': 104, 'max_depth': 3, 'learning_rate': 0.07194884716225267, 'subsample': 0.6803024078585833, 'colsample_bytree': 0.9490970163171296, 'reg_alpha': 4.981977178127451, 'reg_lambda': 1.4825685626648326}. Best is trial 4 with value: 0.3542343410916506.\n",
      "[I 2025-06-26 20:30:36,672] Trial 10 finished with value: 0.35270219517731133 and parameters: {'n_estimators': 284, 'max_depth': 6, 'learning_rate': 0.019060060464976047, 'subsample': 0.9169162652747909, 'colsample_bytree': 0.6194260140941301, 'reg_alpha': 2.863664459726818, 'reg_lambda': 0.008408751662369873}. Best is trial 10 with value: 0.35270219517731133.\n",
      "[I 2025-06-26 20:35:42,892] Trial 11 finished with value: 0.3728075270100695 and parameters: {'n_estimators': 286, 'max_depth': 6, 'learning_rate': 0.01021304343288782, 'subsample': 0.9146948076662413, 'colsample_bytree': 0.605585671026125, 'reg_alpha': 2.975429943592163, 'reg_lambda': 0.1585564603518045}. Best is trial 10 with value: 0.35270219517731133.\n",
      "[I 2025-06-26 20:40:48,589] Trial 12 finished with value: 0.36847897402777974 and parameters: {'n_estimators': 284, 'max_depth': 6, 'learning_rate': 0.011156613441074263, 'subsample': 0.8820694267271633, 'colsample_bytree': 0.6354615972057114, 'reg_alpha': 2.877197031193427, 'reg_lambda': 4.839259259894823}. Best is trial 10 with value: 0.35270219517731133.\n",
      "[I 2025-06-26 20:43:53,694] Trial 13 finished with value: 0.3515775511503152 and parameters: {'n_estimators': 177, 'max_depth': 6, 'learning_rate': 0.03060683591481545, 'subsample': 0.8589111247905646, 'colsample_bytree': 0.9858447727163699, 'reg_alpha': 2.5192785668072806, 'reg_lambda': 3.846719103185947}. Best is trial 13 with value: 0.3515775511503152.\n",
      "[I 2025-06-26 20:47:07,290] Trial 14 finished with value: 0.3469307528744616 and parameters: {'n_estimators': 179, 'max_depth': 6, 'learning_rate': 0.029080986542449484, 'subsample': 0.9944461225588256, 'colsample_bytree': 0.6771174538227589, 'reg_alpha': 3.3779769245525717, 'reg_lambda': 0.17961145310885618}. Best is trial 14 with value: 0.3469307528744616.\n",
      "[I 2025-06-26 20:52:17,628] Trial 15 finished with value: 0.3675413036570994 and parameters: {'n_estimators': 177, 'max_depth': 7, 'learning_rate': 0.031073863745214408, 'subsample': 0.9670475844157339, 'colsample_bytree': 0.9788603405176541, 'reg_alpha': 3.5882967141143416, 'reg_lambda': 3.7247092869500236}. Best is trial 14 with value: 0.3469307528744616.\n",
      "[I 2025-06-26 20:56:50,923] Trial 16 finished with value: 0.36242700924787935 and parameters: {'n_estimators': 133, 'max_depth': 5, 'learning_rate': 0.038463525985447486, 'subsample': 0.9902137238934989, 'colsample_bytree': 0.6853521713725477, 'reg_alpha': 3.3831067288155636, 'reg_lambda': 0.8498227906511739}. Best is trial 14 with value: 0.3469307528744616.\n",
      "[I 2025-06-26 20:59:40,948] Trial 17 finished with value: 0.38966540851491577 and parameters: {'n_estimators': 184, 'max_depth': 4, 'learning_rate': 0.028817212588165574, 'subsample': 0.8233499219635458, 'colsample_bytree': 0.6864361091508673, 'reg_alpha': 4.436816534046246, 'reg_lambda': 3.6823950709153848}. Best is trial 14 with value: 0.3469307528744616.\n",
      "[I 2025-06-26 21:02:19,405] Trial 18 finished with value: 0.3466703343217969 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.04543570127599121, 'subsample': 0.7557430996695718, 'colsample_bytree': 0.7512502625910861, 'reg_alpha': 0.05538848823628717, 'reg_lambda': 0.7580437491272631}. Best is trial 18 with value: 0.3466703343217969.\n",
      "[I 2025-06-26 21:05:21,049] Trial 19 finished with value: 0.3623291594881432 and parameters: {'n_estimators': 136, 'max_depth': 5, 'learning_rate': 0.04510559192150232, 'subsample': 0.7662961420359393, 'colsample_bytree': 0.7353005537409354, 'reg_alpha': 0.4244735231438295, 'reg_lambda': 0.6902643236921183}. Best is trial 18 with value: 0.3466703343217969.\n",
      "[I 2025-06-26 21:08:44,606] Trial 20 finished with value: 0.40566236282652557 and parameters: {'n_estimators': 102, 'max_depth': 7, 'learning_rate': 0.022148211150731276, 'subsample': 0.7414166066632323, 'colsample_bytree': 0.6615279951512512, 'reg_alpha': 0.10917906820889733, 'reg_lambda': 0.7168508120932344}. Best is trial 18 with value: 0.3466703343217969.\n",
      "[I 2025-06-26 21:13:52,830] Trial 21 finished with value: 0.3575229160034646 and parameters: {'n_estimators': 135, 'max_depth': 6, 'learning_rate': 0.04412730523834794, 'subsample': 0.8554239440165902, 'colsample_bytree': 0.7404649728857513, 'reg_alpha': 2.143623130253093, 'reg_lambda': 1.2474349834094012}. Best is trial 18 with value: 0.3466703343217969.\n",
      "[I 2025-06-26 21:17:41,220] Trial 22 finished with value: 0.357290542365117 and parameters: {'n_estimators': 166, 'max_depth': 6, 'learning_rate': 0.02784350104387969, 'subsample': 0.7961809121608067, 'colsample_bytree': 0.8345732080459091, 'reg_alpha': 2.515335919251815, 'reg_lambda': 0.38409760927690917}. Best is trial 18 with value: 0.3466703343217969.\n",
      "[I 2025-06-26 21:22:34,767] Trial 23 finished with value: 0.3446172648256984 and parameters: {'n_estimators': 194, 'max_depth': 6, 'learning_rate': 0.039113831270019855, 'subsample': 0.7281496420336706, 'colsample_bytree': 0.7668425822191841, 'reg_alpha': 3.349682246788232, 'reg_lambda': 3.7795644782878277}. Best is trial 23 with value: 0.3446172648256984.\n",
      "[I 2025-06-26 21:27:52,564] Trial 24 finished with value: 0.35192059344050614 and parameters: {'n_estimators': 205, 'max_depth': 5, 'learning_rate': 0.04541310747194384, 'subsample': 0.7314355958015772, 'colsample_bytree': 0.7731127166770865, 'reg_alpha': 3.4653595330494484, 'reg_lambda': 1.1098494736925497}. Best is trial 23 with value: 0.3446172648256984.\n",
      "[I 2025-06-26 21:33:23,092] Trial 25 finished with value: 0.3540471146158411 and parameters: {'n_estimators': 231, 'max_depth': 7, 'learning_rate': 0.059313587239513944, 'subsample': 0.72489737606204, 'colsample_bytree': 0.7161695681242511, 'reg_alpha': 3.991765164160343, 'reg_lambda': 1.8644001847006961}. Best is trial 23 with value: 0.3446172648256984.\n",
      "[I 2025-06-26 21:37:10,147] Trial 26 finished with value: 0.35515996717916737 and parameters: {'n_estimators': 151, 'max_depth': 6, 'learning_rate': 0.037595955959773456, 'subsample': 0.7717592437987207, 'colsample_bytree': 0.6494214772730476, 'reg_alpha': 3.190017612187572, 'reg_lambda': 0.4258118999211953}. Best is trial 23 with value: 0.3446172648256984.\n",
      "[I 2025-06-26 21:40:04,093] Trial 27 finished with value: 0.3922320207880202 and parameters: {'n_estimators': 195, 'max_depth': 4, 'learning_rate': 0.020572574644587994, 'subsample': 0.8231260628466626, 'colsample_bytree': 0.7646799814698649, 'reg_alpha': 4.525415815924513, 'reg_lambda': 3.2882898300741283}. Best is trial 23 with value: 0.3446172648256984.\n",
      "[I 2025-06-26 21:42:20,991] Trial 28 finished with value: 0.36244247276356256 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.058694196761302594, 'subsample': 0.7202043674907146, 'colsample_bytree': 0.8155696876332404, 'reg_alpha': 3.777756616017757, 'reg_lambda': 4.274509614438134}. Best is trial 23 with value: 0.3446172648256984.\n",
      "[I 2025-06-26 21:45:59,295] Trial 29 finished with value: 0.3674802025561727 and parameters: {'n_estimators': 229, 'max_depth': 6, 'learning_rate': 0.04738009918501537, 'subsample': 0.6228451580566859, 'colsample_bytree': 0.7633638479241681, 'reg_alpha': 4.133314624314644, 'reg_lambda': 2.0662348772414783}. Best is trial 23 with value: 0.3446172648256984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modelo entrenado y guardado\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "# Cargar datos\n",
    "with open(\"datos_entrenamiento.pkl\", \"rb\") as f:\n",
    "    X_train, X_val, y_train, y_val, sample_weight, columnas = pickle.load(f)\n",
    "\n",
    "# Estudio Optuna\n",
    "storage = \"sqlite:///optuna_tn_study_protegido.db\"\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name=\"prediccion_tn1\",\n",
    "    storage=storage,\n",
    "    load_if_exists=True,\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5)\n",
    ")\n",
    "\n",
    "# Objetivo protegido\n",
    "def objective(trial):\n",
    "    try:\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 350),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 7),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 5.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),\n",
    "            'tree_method': 'hist',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'verbosity': 1\n",
    "        }\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "        pred = model.predict(X_val)\n",
    "        return np.sqrt(mean_squared_error(y_val, pred))\n",
    "    except Exception as e:\n",
    "        trial.set_user_attr(\"failed_reason\", str(e))\n",
    "        return float(\"inf\")\n",
    "\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Mejor modelo\n",
    "best_params = study.best_params\n",
    "best_params.update({'tree_method': 'hist', 'random_state': 42})\n",
    "model_final = XGBRegressor(**best_params)\n",
    "model_final.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]), sample_weight=np.log1p(pd.concat([y_train, y_val]) + 1))\n",
    "\n",
    "joblib.dump(model_final, \"modelo_xgb.pkl\")\n",
    "with open(\"mejores_parametros.json\", \"w\") as f:\n",
    "    json.dump(best_params, f)\n",
    "\n",
    "print(\"âœ… Modelo entrenado y guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763f7301-7fe1-4a28-87c9-4e67cb5a6e8b",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Paso 3: Predecir febrero 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700dd3e4-4bf0-49a8-9b83-db53815a647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar modelo y columnas\n",
    "model_final = joblib.load(\"modelo_xgb.pkl\")\n",
    "with open(\"datos_entrenamiento.pkl\", \"rb\") as f:\n",
    "    _, _, _, _, _, columnas = pickle.load(f)\n",
    "\n",
    "# Cargar base original\n",
    "df = pd.read_csv(\"dataset_base_features.csv\", parse_dates=[\"periodo\"])\n",
    "df[\"product_id\"] = df[\"product_id\"].astype(str)\n",
    "\n",
    "# Diciembre â†’ febrero\n",
    "febrero = df[df[\"periodo\"] == \"2019-12-01\"].copy()\n",
    "febrero[\"periodo\"] = pd.to_datetime(\"2020-02-01\")\n",
    "febrero = febrero.groupby(\"product_id\", as_index=False).first()\n",
    "\n",
    "# Lags\n",
    "for i, mes in zip(range(1, 4), [\"2019-12-01\", \"2019-11-01\", \"2019-10-01\"]):\n",
    "    lag_df = (\n",
    "        df[df[\"periodo\"] == mes]\n",
    "        .groupby(\"product_id\", as_index=False)[\"tn\"]\n",
    "        .mean()\n",
    "        .rename(columns={\"tn\": f\"lag_{i}\"})\n",
    "    )\n",
    "    febrero = febrero.merge(lag_df, on=\"product_id\", how=\"left\")\n",
    "\n",
    "# Completar columnas faltantes\n",
    "faltantes = set(columnas) - set(febrero.columns)\n",
    "for col in faltantes:\n",
    "    febrero[col] = 0\n",
    "febrero_X = febrero[columnas]\n",
    "\n",
    "# Predecir y exportar\n",
    "febrero[\"tn_pred\"] = model_final.predict(febrero_X)\n",
    "febrero[[\"product_id\", \"tn_pred\"]].to_csv(\"prediccion_febrero_xgb.csv\", index=False)\n",
    "\n",
    "print(\"âœ… PredicciÃ³n exportada como 'prediccion_febrero_xgb.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgbmgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
